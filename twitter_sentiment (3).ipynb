{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\text{Twitter Moral Corpus} $$\n",
    "$$ \\text{and} $$\n",
    "$$ \\text{H2O's Python Client with Driverless AI} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes H2O's Driverless AI and related Python Client to analyze the Twitter Corpus Paper 'Moral Foundations Twitter Corpus: A collection of 35k tweets annotated for moralsentiment.' The goal is to analyze the Twitter Moral Corpus and test the efficacy and usability of H2O's automated machine learning through their H2O Ai Client.  \n",
    "\n",
    "Moral Foundations Theory is a five factor taxonomy of human morality. Below are the five.\n",
    "\n",
    "Moral Factors:\n",
    "- Care\\Harm\n",
    "- Fairness\\Cheating\n",
    "- Loyalty\\Betrayal\n",
    "- Authority\\Subversion\n",
    "- Purity\\Degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import wget #!pip install wget\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile \n",
    "from h2oai_client import Client\n",
    "from sklearn import model_selection\n",
    "\n",
    "# pd.set_option('display.max_rows', None), pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download twitter data with tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget.download('https://drive.google.com/u/0/uc?id=1d1p95CspLTT1em4I42rDpWY6Hcikg296&export=download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter data doesn't come with tweets. In order to get the tweets you have to sign up for a twitter develop account. \n",
    "\n",
    "You will need to collect the following and fill in the values in the text_script before you run it with python text_script.py. The tweets will then be populated. <br>\n",
    "Values to be filled: consumer_key='', consumer_secret='', access_token_key='', access_token_secret=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter sentiment data\n",
    "# wget.download('https://osf.io/cwu4m/download')\n",
    "# os.rename('MFTC_V4.json', 'twitter_sentiment.json')\n",
    "\n",
    "# Text script\n",
    "# wget.download('https://osf.io/mzg5w/download')\n",
    "# !python text_scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The davidson comes separate. Below will download that; however, this was left out because the word classications weren't available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wget for Davidson dataset mentioned below\n",
    "# wget.download('https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/ \\\n",
    "# master/data/labeled_data.csv')\n",
    "# df_davidson = pd.read_csv('labeled_data.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set credentials for H2O Client. The username will be the beginning of the email used for your GCP account. You can also type ‘id’ into the terminal and that will show the username, i.e. uid=1001(username). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'http://34.106.56.14:12345'\n",
    "username = 'scidataprojects'\n",
    "password = 'Cypher65!@'\n",
    "h2oai = Client(address = address, username = username, password = password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import moral corpus', below is each given corpus. The Davidson corpus needed to be downloaded from elsewhere, and didn't have the actual classification words included so was ultimately excluded from the analysis.  \n",
    "\n",
    "Domains are selected based on relevant moral problems in social sciences.\n",
    "- ALM: All Lives Matter - political right\n",
    "- Baltimore: Baltimore protests related to the death of Freddie Gray.\n",
    "- BLM: Black Lives Matter - political left\n",
    "- Election: The 2016 presidential election\n",
    "- MeToo: Womens sexual harassment/assualt movement. \n",
    "- Sandy: Hurricane Sandy\n",
    "- Davidson: Hate Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('tw.json')\n",
    "dfs = []\n",
    "ALM, Baltimore, BLM, Election, MeToo, Sandy = df['Tweets'][0], df['Tweets'][1], df['Tweets'][2], \\\n",
    "                                              df['Tweets'][4], df['Tweets'][5], df['Tweets'][6]\n",
    "\n",
    "corpus = [ALM, Baltimore, BLM, Election, MeToo, Sandy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domains come embedded in a json file. For ease of use, the below code takes the json and places it in a pandas dataframe. All hash tags were removed from the tweets. Each tweet has the potential to have multiple word classifications based on the aforementioned moral theory factors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial lists to be converted to a dataframe later\n",
    "text_id = []\n",
    "tweet = []\n",
    "date = []\n",
    "annotation = []\n",
    "\n",
    "for c in corpus:\n",
    "    for i in c:\n",
    "        text_id.append(list(i.values())[0])\n",
    "        tweet.append(list(i.values())[1])\n",
    "        date.append(list(i.values())[2])\n",
    "        annotation.append(list(i.values())[3])\n",
    "\n",
    "tweet = pd.DataFrame(tweet, columns=['tweet'])\n",
    "text_id = pd.DataFrame(text_id, columns=['text_id'])\n",
    "date = pd.DataFrame(date, columns=['date'])\n",
    "\n",
    "frst_column_annotations = []\n",
    "scnd_column_annotations = []\n",
    "\n",
    "\n",
    "for i in annotation:\n",
    "    frst_column_annotations.append(list(i[0].values())[1])\n",
    "    scnd_column_annotations.append(list(i[1].values())[1])\n",
    "\n",
    "dataframe_a_words = pd.DataFrame(frst_column_annotations, columns=['word1'])\n",
    "dataframe_b_words = pd.DataFrame(scnd_column_annotations, columns=['word2'])\n",
    "words = pd.concat([dataframe_a_words, dataframe_b_words], axis=1)\n",
    "\n",
    "words_col_a = words['word1'].str.split(',', 4, expand=True).rename(columns={0:'w1', 1:'w2', 2:'w3', 3:'w4', 4:'w5'})\n",
    "words_col_b = words['word2'].str.split(',', 5, expand=True).rename(columns={0:'w6', 1:'w7', 2:'w8', 3:'w9', 4:'w10', 5:'w11'})\n",
    "words_df = pd.concat([words_col_a, words_col_b], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "text_id = pd.DataFrame(text_id, columns=['text_id'])\n",
    "tweet = pd.DataFrame(tweet, columns=['tweet'])\n",
    "date = pd.DataFrame(date, columns=['date'])\n",
    "\n",
    "df_list = [text_id, tweet, date, words_df]\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df_words = pd.concat(df_list, axis=1)\n",
    "\n",
    "df.drop(columns=['text_id', 'date'], inplace=True)\n",
    "df = df[df['tweet'] != 'no tweet text available']\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df['tweet'] = df['tweet'].str.replace('#\\S+', '', regex=True) \\\n",
    "                         .str.replace('&amp;','and') \\\n",
    "                         .str.strip()\n",
    "\n",
    "is_duplicate = df.apply(pd.Series.duplicated, axis=1)\n",
    "df_ = df.where(~is_duplicate, None)\n",
    "\n",
    "dataframe = df_[['tweet','w1']].rename(columns={'w1':'Annotations'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that all columns have a max of one word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in df_.iloc[:,1:]:\n",
    "#     print(df_[x].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df.iloc[:,1:])\n",
    "dummies_summed = dummies.iloc[:,1:].T.groupby([s.split('_')[1] for s in dummies.iloc[:,1:].T.index.values]).sum().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2632,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each pair of moral values, if there is a value in each field greater than zero take the higher of the two.\n",
    "def set_higher_moral_count(col1, col2):\n",
    "    if col1 > 0:\n",
    "        return 1\n",
    "    elif col2 > 0:\n",
    "        return 0\n",
    "    # Check if both columns are > 0 and equal\n",
    "    elif col1 > 0 & col2 > 0 & col1 == col2:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "care_harm = dummies_summed.apply(lambda x: set_higher_moral_count(x.harm, x.care), axis=1)\n",
    "fairness_cheating = dummies_summed.apply(lambda x: set_higher_moral_count(x.fairness, x.cheating), axis=1)\n",
    "loyalty_betrayal = dummies_summed.apply(lambda x: set_higher_moral_count(x.loyalty, x.betrayal), axis=1)\n",
    "authority_subversion = dummies_summed.apply(lambda x: set_higher_moral_count(x.authority, x.subversion), axis=1)\n",
    "purity_degradation = dummies_summed.apply(lambda x: set_higher_moral_count(x.purity, x.degradation), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2632,), (2632,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, care_harm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Wholeheartedly support these protests and acts...\n",
       "1    This Sandra Bland situation man no disrespect ...\n",
       "2    Commitment to peace, healing and loving neighb...\n",
       "3            Injustice for one is an injustice for all\n",
       "4    This is what compassion looks like!   https://...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Care_Harm = pd.concat([y, care_harm], axis=1)[care_harm != 2].rename(columns={0:'y'}).reset_index(drop=True)\n",
    "Fairness_Cheating = pd.concat([y, fairness_cheating], axis=1)[fairness_cheating != 2].rename(columns={0:'y'}).reset_index(drop=True)\n",
    "Loyalty_Betrayal = pd.concat([y, loyalty_betrayal], axis=1)[loyalty_betrayal != 2].rename(columns={0:'y'}).reset_index(drop=True)\n",
    "Authority_Subversion = pd.concat([y, authority_subversion], axis=1)[authority_subversion != 2].rename(columns={0:'y'}).reset_index(drop=True)\n",
    "Purity_Degradation = pd.concat([y, purity_degradation], axis=1)[purity_degradation != 2].rename(columns={0:'y'}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for value counts and imbalanced classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = First listed value\n",
      "0 = Second listed value\n",
      "-----------\n",
      "Care_Harm\n",
      "1    662\n",
      "0    466\n",
      "Name: y, dtype: int64 \n",
      "\n",
      "Fairness_Cheating\n",
      "1    659\n",
      "0    532\n",
      "Name: y, dtype: int64 \n",
      "\n",
      "Loyalty_Betrayal\n",
      "1    462\n",
      "0    351\n",
      "Name: y, dtype: int64 \n",
      "\n",
      "Authority_Subversion\n",
      "0    247\n",
      "1    108\n",
      "Name: y, dtype: int64 \n",
      "\n",
      "Purity_Degradation\n",
      "1    267\n",
      "0    160\n",
      "Name: y, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "frames = [Care_Harm, Fairness_Cheating, Loyalty_Betrayal, Authority_Subversion, Purity_Degradation]\n",
    "names = ['Care_Harm', 'Fairness_Cheating', 'Loyalty_Betrayal', 'Authority_Subversion', 'Purity_Degradation']\n",
    "\n",
    "print('1 = First listed value')\n",
    "print('0 = Second listed value\\n-----------')\n",
    "\n",
    "for w,z in zip(names, frames):\n",
    "    print(w)\n",
    "    print(z.iloc[:, 1].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "\n",
    "def train_test_split(names, frames):\n",
    "#     Split dataset into test and train sets. We use numpy to split the data then export to csv files. <br>\n",
    "#     70/30 split\n",
    "    for name,frame in zip(names, frames):\n",
    "        train, test = np.split(frame.sample(frac=1), [int(.7*len(frame))])\n",
    "        train.reset_index(inplace=True, drop=True)\n",
    "        test.reset_index(inplace=True, drop=True)\n",
    "        train.to_csv(\"train_twitter_sentiment{}.csv\".format(name), index=False)\n",
    "        test.to_csv(\"test_twitter_sentiment{}.csv\".format(name), index=False)\n",
    "        \n",
    "        return train, test\n",
    "\n",
    "\n",
    "def train_and_download_summary(name):\n",
    "    start = time.time()\n",
    "    \n",
    "    train, test = train_test_split(names, frames)\n",
    "    name = get_df_name(name)\n",
    "    \n",
    "    train_path = './train_twitter_sentiment{}.csv'.format(name)\n",
    "    test_path = './test_twitter_sentiment{}.csv'.format(name)\n",
    "    \n",
    "    # Pull in the data and place into the h20ai client to utilize their classes/tools. \n",
    "    train = h2oai.upload_dataset_sync(train_path)\n",
    "    test = h2oai.upload_dataset_sync(test_path)\n",
    " \n",
    "    # Run the model\n",
    "    model = h2oai.start_experiment_sync(\n",
    "        dataset_key=train.key,\n",
    "        testset_key=test.key,\n",
    "        target_col='y',\n",
    "        scorer='LOGLOSS',\n",
    "        is_classification=True,\n",
    "        cols_to_drop=[],\n",
    "        accuracy=7,\n",
    "        time=2,\n",
    "        interpretability=8,\n",
    "        enable_gpus=True,\n",
    "        config_overrides=\"\"\"\n",
    "                        enable_tensorflow='on'\n",
    "                        enable_tensorflow_charcnn='on'\n",
    "                        enable_tensorflow_textcnn='on'\n",
    "                        enable_tensorflow_textbigru='on'\n",
    "                        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Download summary files and place in the 'summary' folder.   \n",
    "    name = get_df_name(name)\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    path = os.path.isdir(cwd+'/'+'summary_'+name)\n",
    "    if not path:\n",
    "        os.mkdir('summary_'+name)\n",
    "        \n",
    "    summary_path = h2oai.download(src_path=model.summary_path, dest_dir='.')\n",
    "    dir_path = './h2oai_experiment_summary_'+model.key\n",
    "\n",
    "\n",
    "    with ZipFile(dir_path+'.zip', 'r') as zip: \n",
    "        zip.extractall('./summary{}/'.format(name))\n",
    "        \n",
    "    end = time.time()\n",
    "    print(end -start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Care_Harm\n",
    "# Fairness_Cheating\n",
    "# Loyalty_Betrayal\n",
    "# Authority_Subversion\n",
    "# Purity_Degradation\n",
    "\n",
    "train_and_download_summary(Care_Harm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_base_learner_fold_scores = pd.read_json('summary/ensemble_base_learner_fold_scores.json')\n",
    "timing = pd.read_json('summary/timing.json')\n",
    "coefs = pd.read_json('summary/coefs.json')\n",
    "confsn_mtrx = pd.read_json('summary/ensemble_confusion_matrix_test.json')\n",
    "orig_features = pd.read_json('summary/ensemble_features_orig.json')\n",
    "ensemble_features = pd.read_json('summary/ensemble_features.json')\n",
    "ensemble_model_description = pd.read_json('summary/ensemble_model_description.json')\n",
    "ensemble_score_data = pd.read_json('summary/ensemble_score_data.json').T\n",
    "tuning_leaderboard = pd.read_json('summary/tuning_leaderboard.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
